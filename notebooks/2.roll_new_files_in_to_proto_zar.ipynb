{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load common functions, libs and vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version - 15/02/19 14:19\n"
     ]
    }
   ],
   "source": [
    "print(\"version - 15/02/19 14:19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/intake/source/discovery.py:39: UserWarning: Plugin name collision for \"netcdf\" from\n",
      "    /opt/conda/lib/python3.6/site-packages/intake_iris/netcdf.py\n",
      "and\n",
      "    /opt/conda/lib/python3.6/site-packages/intake_xarray/netcdf.py\n",
      "Keeping plugin from first location.\n",
      "  % (plugin_name, orig_path, new_path))\n"
     ]
    }
   ],
   "source": [
    "# %load common.py\n",
    "import iris\n",
    "import xarray\n",
    "import os\n",
    "from numcodecs import Blosc\n",
    "import s3fs\n",
    "import zarr\n",
    "import intake\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import cf_units\n",
    "import json\n",
    "import  dask_kubernetes\n",
    "import distributed\n",
    "import boto3\n",
    "from iris.experimental.equalise_cubes import equalise_attributes\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.normpath(os.getcwd()))\n",
    "from offsetmap import OffSetS3Map\n",
    "\n",
    "sqs = boto3.client('sqs')\n",
    "\n",
    "AWS_EARTH_TIME_FORMAT = '%Y-%m-%dT%H:%M:%SZ'\n",
    "# SQS_QUEUE_URL = 'https://sqs.eu-west-2.amazonaws.com/536099501702/aws-earth-test'\n",
    "SQS_QUEUE_URL = 'https://sqs.eu-west-2.amazonaws.com/536099501702/rolling_zarr_test_queue'\n",
    "\n",
    "BUCKET = \"metoffice-aws-earth-zarr\"\n",
    "\n",
    "def del_msg(msg):\n",
    "    sqs.delete_message(\n",
    "        QueueUrl=SQS_QUEUE_URL,\n",
    "        ReceiptHandle=msg['receipt_handle']\n",
    "    )\n",
    "    \n",
    "def get_messages(max_num=10):\n",
    "    res = sqs.receive_message(QueueUrl=SQS_QUEUE_URL, MaxNumberOfMessages=max_num, VisibilityTimeout=60*10)\n",
    "    messages  = []\n",
    "    for message in res['Messages']:\n",
    "        msg = json.loads(message['Body'])\n",
    "        msg['receipt_handle'] = message['ReceiptHandle']\n",
    "        messages.append(msg)\n",
    "    return messages\n",
    "\n",
    "def get_zar_path(meta):\n",
    "    base = f\"{BUCKET}/{meta['model']}-{meta['name']}\"\n",
    "    if meta.get('cell_methods', False):\n",
    "        base += f\"-{meta['cell_methods']}\"\n",
    "    if  meta.get('height', False) and (len(meta['height'].strip().split(' ')) > 1):\n",
    "        base += '-at_heights'\n",
    "    if meta.get('pressure', False) and (len(meta['pressure'].strip().split(' ')) > 1):\n",
    "        base += '-at_pressures'\n",
    "    return base + '.zarr'\n",
    "    \n",
    "\n",
    "def zarr_store(meta):\n",
    "    return OffSetS3Map(root=get_zar_path(meta), temp_chunk_path=meta['name'], check=False)\n",
    "    \n",
    "def msg_to_path(msg):\n",
    "    return f'/s3/{msg[\"bucket\"]}/{msg[\"key\"]}'\n",
    "\n",
    "def reshape_to_dest_cube(cube):\n",
    "    return iris.util.new_axis(iris.util.new_axis(cube, 'forecast_period'), 'forecast_reference_time')\n",
    "\n",
    "\n",
    "def get_proto_zarr_array(meta):\n",
    "    OffSetS3Map(root=get_zar_path(meta), temp_chunk_path=meta['name'], check=False)\n",
    "    array_store = OffSetS3Map(root=get_zar_path(meta) +'/' + meta['name'], temp_chunk_path='', check=False)\n",
    "    return zarr.open(array_store)\n",
    "\n",
    "\n",
    "# def get_messages_like(max_try=500,**filters):\n",
    "#     \"\"\"filters: Value of True means has key and is not False. value of None means doesn't have key or value is None. Anyother value is a straight mathch\"\"\"\n",
    "    \n",
    "#     def match(msg):\n",
    "#         for key, value in filters.items():\n",
    "#             if callable(value):\n",
    "#                 if not value(msg.get(key,None)):\n",
    "#                     return False\n",
    "#             elif not msg.get(key,None) == value:\n",
    "#                 return False\n",
    "#         return True\n",
    "\n",
    "#     attempt = 0\n",
    "#     msg = None\n",
    "#     while attempt < max_try:\n",
    "#         attempt +=1\n",
    "#         for msg in [m['Message'] for m in get_messages(10)[1]]:\n",
    "#             msg = json.loads(msg)\n",
    "#             if match(msg):\n",
    "#                 yield msg\n",
    "\n",
    "\n",
    "# sample_sns_message = {\n",
    "#     'model': 'mo-atmospheric-mogreps-g-prd',\n",
    "#     'ttl': 1544268873,\n",
    "#     'time': '2018-12-13T09:00:00Z',\n",
    "#     'created_time': '2018-12-06T11:22:27Z',\n",
    "#     'name': 'air_temperature',\n",
    "#     'object_size': 711463962,\n",
    "#     'forecast_period': 615600,\n",
    "#     'forecast_reference_time': '2018-12-06T06:00:00Z',\n",
    "#     'pressure': '100000.0 97500.0 95000.0 92500.0 90000.0 85000.0 80000.0 75000.0 70000.0 65000.0 60000.0 55000.0 50000.0 45000.0 40000.0 37500.0 35000.0 32500.0 30000.0 27500.0 25000.0 22500.0 20000.0 17500.0 15000.0 12500.0 10000.0 7000.0 5000.0 4000.0 3000.0 2000.0 1000.0',\n",
    "#     'forecast_period_units': 'seconds',\n",
    "#     'pressure_units': 'Pa',\n",
    "#     'bucket': 'aws-earth-mo-examples',\n",
    "#     'key': 'cafef7005477edb001aa7dc50eab78c5ef89d420.nc',\n",
    "#     'realization': '0 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34'\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process new incoming file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_time': '2019-02-14T06:59:35Z',\n",
       " 'forecast_period': '10800',\n",
       " 'forecast_period_units': 'seconds',\n",
       " 'height_units': 'm',\n",
       " 'ttl': '1550369304',\n",
       " 'realization': '0 1 2 3 4 5 6 7 8 9 10 11',\n",
       " 'bucket': 'informatics-aws-earth-staging',\n",
       " 'forecast_reference_time': '2019-02-14T03:00:00Z',\n",
       " 'name': 'air_temperature',\n",
       " 'model': 'mo-atmospheric-mogreps-uk-prd',\n",
       " 'time': '2019-02-14T06:00:00Z',\n",
       " 'key': '71ef822facc9efd00829c570fa6cfc822791797d.nc',\n",
       " 'object_size': '323943448',\n",
       " 'height': '5.0 10.0 20.0 30.0 50.0 75.0 100.0 150.0 200.0 250.0 300.0 400.0 500.0 600.0 700.0 800.0 1000.0 1250.0 1500.0 1750.0 2000.0 2250.0 2500.0 2750.0 3000.0 3250.0 3500.0 3750.0 4000.0 4500.0 5000.0 5500.0 6000.0',\n",
       " 'receipt_handle': 'AQEBvODEplTVODCi1vvYBb/ivzmChFEy+13eG43Olfs2JIg1h2UcSYuZjnIfHhLlDleyqfgPJbjSZjpVm6iQxs22RVpMW+Gc5q7UKL39I6RqXsQ5dmtp+mcc7dI17BFzGcLkPTytb839ED6+3h2RjbRZNQgPG7AxEtGY+TPbgREG5K4WZUoz7cmE1ERz8a77gYow0E+5ZPHeD0DAXYwrgxEMgixRsO8WfHlNkbjtWj8MVfH1f1Ft9crqUHiwxDqTK9iXUlbPKhz3Ef/pxtcNYn4lwhBAzWRsJq2hDkRxNjItO8AGqYfAaLHkcYO+e3Tu0potnA06FiqLxVhhXlkyUepqRlbeIRYdIJHkwHz5Thm/CgnF1aJa0JG+eUXcgzKM95mIKfbakEfDljVdPFadKTF0vg=='}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs = get_messages(1)\n",
    "assert len(msgs) >= 1, \"No messages recived\"\n",
    "    \n",
    "msg = msgs[0]\n",
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "do_download = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import uuid\n",
    "\n",
    "def download(msg):\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(msg['bucket'])\n",
    "    key = msg['key']\n",
    "    dest = os.path.join(f'./{uuid.uuid4().hex}.nc')\n",
    "    with open(dest,'wb') as fp:\n",
    "        fp.write(bucket.Object(key).get()['Body'].read())\n",
    "    print(dest)\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./33ce2b55dbb441c4a48818f1e079343a.nc\n",
      "Work with file at ./33ce2b55dbb441c4a48818f1e079343a.nc\n"
     ]
    }
   ],
   "source": [
    "if do_download:\n",
    "    file_path = download(msg)\n",
    "else:\n",
    "    file_path = msg_to_path(msg)\n",
    "print (f\"Work with file at {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run is 2019-02-14 03:00:00\n",
      "forecast_period is 10800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  a.iris {\n",
       "      text-decoration: none !important;\n",
       "  }\n",
       "  table.iris {\n",
       "      white-space: pre;\n",
       "      border: 1px solid;\n",
       "      border-color: #9c9c9c;\n",
       "      font-family: monaco, monospace;\n",
       "  }\n",
       "  th.iris {\n",
       "      background: #303f3f;\n",
       "      color: #e0e0e0;\n",
       "      border-left: 1px solid;\n",
       "      border-color: #9c9c9c;\n",
       "      font-size: 1.05em;\n",
       "      min-width: 50px;\n",
       "      max-width: 125px;\n",
       "  }\n",
       "  tr.iris :first-child {\n",
       "      border-right: 1px solid #9c9c9c !important;\n",
       "  }\n",
       "  td.iris-title {\n",
       "      background: #d5dcdf;\n",
       "      border-top: 1px solid #9c9c9c;\n",
       "      font-weight: bold;\n",
       "  }\n",
       "  .iris-word-cell {\n",
       "      text-align: left !important;\n",
       "      white-space: pre;\n",
       "  }\n",
       "  .iris-subheading-cell {\n",
       "      padding-left: 2em !important;\n",
       "  }\n",
       "  .iris-inclusion-cell {\n",
       "      padding-right: 1em !important;\n",
       "  }\n",
       "  .iris-panel-body {\n",
       "      padding-top: 0px;\n",
       "  }\n",
       "  .iris-panel-title {\n",
       "      padding-left: 3em;\n",
       "  }\n",
       "  .iris-panel-title {\n",
       "      margin-top: 7px;\n",
       "  }\n",
       "</style>\n",
       "<table class=\"iris\" id=\"140100311839576\">\n",
       "    <tr class=\"iris\">\n",
       "<th class=\"iris iris-word-cell\">Air Temperature (K)</th>\n",
       "<th class=\"iris iris-word-cell\">forecast_reference_time</th>\n",
       "<th class=\"iris iris-word-cell\">forecast_period</th>\n",
       "<th class=\"iris iris-word-cell\">realization</th>\n",
       "<th class=\"iris iris-word-cell\">height</th>\n",
       "<th class=\"iris iris-word-cell\">projection_y_coordinate</th>\n",
       "<th class=\"iris iris-word-cell\">projection_x_coordinate</th>\n",
       "</tr>\n",
       "    <tr class=\"iris\">\n",
       "<td class=\"iris-word-cell iris-subheading-cell\">Shape</td>\n",
       "<td class=\"iris iris-inclusion-cell\">1</td>\n",
       "<td class=\"iris iris-inclusion-cell\">1</td>\n",
       "<td class=\"iris iris-inclusion-cell\">12</td>\n",
       "<td class=\"iris iris-inclusion-cell\">33</td>\n",
       "<td class=\"iris iris-inclusion-cell\">970</td>\n",
       "<td class=\"iris iris-inclusion-cell\">1042</td>\n",
       "</td>\n",
       "    <tr class=\"iris\">\n",
       "    <td class=\"iris-title iris-word-cell\">Dimension coordinates</td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tforecast_reference_time</td>\n",
       "    <td class=\"iris-inclusion-cell\">x</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tforecast_period</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">x</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\trealization</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">x</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\theight</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">x</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tprojection_y_coordinate</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">x</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tprojection_x_coordinate</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">-</td>\n",
       "    <td class=\"iris-inclusion-cell\">x</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-title iris-word-cell\">Scalar coordinates</td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\ttime</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"6\">2019-02-14 06:00:00</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-title iris-word-cell\">Attributes</td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "    <td class=\"iris-title\"></td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tConventions</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"6\">CF-1.5, UKMO-1.0</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\thistory</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"6\">2019-02-14T06:59:35Z: StaGE Decoupler</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tinstitution</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"6\">Met Office</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tleast_significant_digit</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"6\">1.0</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tmosg__forecast_run_duration</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"6\">PT54H</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tmosg__grid_domain</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"6\">uk_extended</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tmosg__grid_type</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"6\">standard</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tmosg__grid_version</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"6\">1.3.0</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tmosg__model_configuration</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"6\">uk_ens</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tsource</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"6\">Met Office Unified Model</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\ttitle</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"6\">MOGREPS-UK Model Forecast on UK 2 km Standard Grid</td>\n",
       "</tr>\n",
       "<tr class=\"iris\">\n",
       "    <td class=\"iris-word-cell iris-subheading-cell\">\tum_version</td>\n",
       "    <td class=\"iris-word-cell\" colspan=\"6\">10.9</td>\n",
       "</tr>\n",
       "</table>\n",
       "        "
      ],
      "text/plain": [
       "<iris 'Cube' of air_temperature / (K) (forecast_reference_time: 1; forecast_period: 1; realization: 12; height: 33; projection_y_coordinate: 970; projection_x_coordinate: 1042)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_to_add = reshape_to_dest_cube(iris.load_cube(file_path))\n",
    "print(f\"Run is {list(cube_to_add.coord('forecast_reference_time').cells())[0].point}\")\n",
    "print(f\"forecast_period is {list(cube_to_add.coord('forecast_period').cells())[0].point}\")\n",
    "cube_to_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## work out offset\n",
    "Look at the `_origin` of the zarr and calculate how far from the origin the current file is. This is our offset that we need when defining the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for forecast_reference_time offset is  120.0\n",
      "for forecast_period offset is  3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[120, 3, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_zarr = get_proto_zarr_array(msg)\n",
    "origin = dest_zarr.attrs['_origin']\n",
    "offsets = []\n",
    "try:\n",
    "    for i,dim in enumerate(origin):\n",
    "        coord = cube_to_add.coord(dim['name'])\n",
    "        step = dim.get('step', None)\n",
    "        if step:\n",
    "            assert dim['unit'] == str(coord.units), \"units are not same %s != %s\" % (dim['unit'], coord.units) # units must be same\n",
    "            diff = coord.points[0] - dim['at']\n",
    "            assert diff >= 0, \"index would be negative: origin: %s, point: %s\" % ( dim['at'], coord.points[0]) # diff must be in the +ve direction zarr doesn't -ve index\n",
    "            offset  = diff / step / dest_zarr.chunks[i]\n",
    "            assert offset % 1 == 0 # offset must be an int. index can't be fractional.\n",
    "            print(\"for\", coord.name(), \"offset is \", offset)\n",
    "            offsets += [int(offset)]\n",
    "        else:\n",
    "            offsets += [int(0)]\n",
    "except AssertionError as e:\n",
    "    del_msg(msg)\n",
    "    raise\n",
    "        \n",
    "    \n",
    "offsets   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array<rechunk-merge, shape=(1, 1, 12, 33, 970, 1042), dtype=float32, chunksize=(1, 1, 3, 11, 970, 1042)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cube_to_add.lazy_data()\n",
    "data = data.rechunk(dest_zarr.chunks)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write new chunks\n",
    "'loop' over all blocks in the file and save them to their new index in the rolling zarr array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a cluster. Need to ensure it has write access to the write dest of the Zarr, hence using the template which has AWS keys in as Env vars\n",
    "# import dask_kubernetes\n",
    "# import distributed\n",
    "# dask_worker_template = os.path.expanduser(\"~/ota/small-worker-template.yaml\")\n",
    "# cluster = dask_kubernetes.KubeCluster.from_yaml(dask_worker_template)\n",
    "# cluster.adapt(minimum=0,maximum=40)\n",
    "# c = distributed.Client(cluster)\n",
    "# cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_write = datetime.now()\n",
    "# def process_block(block, block_info=None):\n",
    "#     print(block_info)\n",
    "#     cloc = block_info[0]['chunk-location']\n",
    "#     to_cloc = [o+i for o, i in zip(offsets, cloc)]\n",
    "#     key = '.'.join(f\"{int(i):d}\" for i in to_cloc )\n",
    "#     dest_zarr.store[key] = dest_zarr._encode_chunk(block)\n",
    "#     print(\"Done block\")\n",
    "#     return block\n",
    "        \n",
    "# data.map_blocks(process_block, dtype=data.dtype).compute()\n",
    "# end_write = datetime.now()\n",
    "# f\"Blocks write took {end_write - start_write}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop axis: [0, 1, 4, 5]. New output shape: [1, 1], in chunks [1, 1]\n",
      "{0: {'shape': (1, 1, 12, 33, 970, 1042), 'num-chunks': (1, 1, 4, 3, 1, 1), 'array-location': [(0, 1), (0, 1), (0, 3), (22, 33), (0, 970), (0, 1042)], 'chunk-location': (0, 0, 0, 2, 0, 0)}}\n",
      "Done block\n",
      "{0: {'shape': (1, 1, 12, 33, 970, 1042), 'num-chunks': (1, 1, 4, 3, 1, 1), 'array-location': [(0, 1), (0, 1), (9, 12), (0, 11), (0, 970), (0, 1042)], 'chunk-location': (0, 0, 3, 0, 0, 0)}}\n",
      "Done block\n",
      "{0: {'shape': (1, 1, 12, 33, 970, 1042), 'num-chunks': (1, 1, 4, 3, 1, 1), 'array-location': [(0, 1), (0, 1), (6, 9), (0, 11), (0, 970), (0, 1042)], 'chunk-location': (0, 0, 2, 0, 0, 0)}}\n",
      "Done block\n",
      "{0: {'shape': (1, 1, 12, 33, 970, 1042), 'num-chunks': (1, 1, 4, 3, 1, 1), 'array-location': [(0, 1), (0, 1), (6, 9), (22, 33), (0, 970), (0, 1042)], 'chunk-location': (0, 0, 2, 2, 0, 0)}}\n",
      "Done block\n",
      "{0: {'shape': (1, 1, 12, 33, 970, 1042), 'num-chunks': (1, 1, 4, 3, 1, 1), 'array-location': [(0, 1), (0, 1), (3, 6), (0, 11), (0, 970), (0, 1042)], 'chunk-location': (0, 0, 1, 0, 0, 0)}}\n",
      "Done block\n",
      "{0: {'shape': (1, 1, 12, 33, 970, 1042), 'num-chunks': (1, 1, 4, 3, 1, 1), 'array-location': [(0, 1), (0, 1), (3, 6), (11, 22), (0, 970), (0, 1042)], 'chunk-location': (0, 0, 1, 1, 0, 0)}}\n",
      "Done block\n",
      "{0: {'shape': (1, 1, 12, 33, 970, 1042), 'num-chunks': (1, 1, 4, 3, 1, 1), 'array-location': [(0, 1), (0, 1), (6, 9), (11, 22), (0, 970), (0, 1042)], 'chunk-location': (0, 0, 2, 1, 0, 0)}}\n",
      "Done block\n",
      "{0: {'shape': (1, 1, 12, 33, 970, 1042), 'num-chunks': (1, 1, 4, 3, 1, 1), 'array-location': [(0, 1), (0, 1), (0, 3), (11, 22), (0, 970), (0, 1042)], 'chunk-location': (0, 0, 0, 1, 0, 0)}}\n",
      "Done block\n",
      "{0: {'shape': (1, 1, 12, 33, 970, 1042), 'num-chunks': (1, 1, 4, 3, 1, 1), 'array-location': [(0, 1), (0, 1), (9, 12), (22, 33), (0, 970), (0, 1042)], 'chunk-location': (0, 0, 3, 2, 0, 0)}}\n",
      "Done block\n",
      "{0: {'shape': (1, 1, 12, 33, 970, 1042), 'num-chunks': (1, 1, 4, 3, 1, 1), 'array-location': [(0, 1), (0, 1), (3, 6), (22, 33), (0, 970), (0, 1042)], 'chunk-location': (0, 0, 1, 2, 0, 0)}}\n",
      "Done block\n",
      "{0: {'shape': (1, 1, 12, 33, 970, 1042), 'num-chunks': (1, 1, 4, 3, 1, 1), 'array-location': [(0, 1), (0, 1), (9, 12), (11, 22), (0, 970), (0, 1042)], 'chunk-location': (0, 0, 3, 1, 0, 0)}}\n",
      "Done block\n",
      "{0: {'shape': (1, 1, 12, 33, 970, 1042), 'num-chunks': (1, 1, 4, 3, 1, 1), 'array-location': [(0, 1), (0, 1), (0, 3), (0, 11), (0, 970), (0, 1042)], 'chunk-location': (0, 0, 0, 0, 0, 0)}}\n",
      "Done block\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Blocks write took 0:02:17.187724'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This cell has got more complicated than desired (original above) because it was failing after \n",
    "processing all chunks when running on papermill as a Kubernettes cron job. \n",
    "The hypothysis is that it was running out of memorry so this tries to shrink the \n",
    "output right down.\n",
    "\n",
    "Turns out the error was acctually because of different container versions was 0.5.14 but should be informaticslab/pangeo-notebook:0.5.13.\n",
    "\n",
    "However, kept this in as it \"feels\" like to make things quicker.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "start_write = datetime.now()\n",
    "def process_block(block, block_info=None, out_shape=None):\n",
    "    print(block_info)\n",
    "    cloc = block_info[0]['chunk-location']\n",
    "    to_cloc = [o+i for o, i in zip(offsets, cloc)]\n",
    "    key = '.'.join(f\"{int(i):d}\" for i in to_cloc )\n",
    "    dest_zarr.store[key] = dest_zarr._encode_chunk(block)\n",
    "    print(\"Done block\")\n",
    "    return np.zeros(out_shape)\n",
    "        \n",
    "    \n",
    "drop_axis = [index for index, sizes in enumerate(data.chunks) if len(sizes) == 1]\n",
    "out_shape = [1 for i in range(len(data.shape) - len(drop_axis))]\n",
    "new_chunks = [1 for i in range(len(out_shape))]\n",
    "\n",
    "print(f\"drop axis: {drop_axis}. New output shape: {out_shape}, in chunks {new_chunks}\")\n",
    "dummy = data.map_blocks(process_block, \n",
    "                dtype=data.dtype,\n",
    "                chunks=new_chunks,\n",
    "                out_shape = out_shape,\n",
    "                drop_axis=drop_axis).compute()\n",
    "end_write = datetime.now()\n",
    "f\"Blocks write took {end_write - start_write}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del c\n",
    "# del cluster\n",
    "# dask.config.set(scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocks written\n",
      "Try delete file\n"
     ]
    }
   ],
   "source": [
    "print(\"Blocks written\")\n",
    "if do_download:\n",
    "    try:\n",
    "        print(\"Try delete file\")\n",
    "        os.remove(file_path)\n",
    "    except IOError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk adding done - delete the message\n",
    "We've now added all the chunks from that file. We could repeate the above for all files. However untill the metadata is updated these extra chunks won't be represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing done. Delete message\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing done. Delete message\")\n",
    "del_msg(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'End'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"End\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
